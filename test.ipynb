{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(-0.13267342746257782,\n",
       "  0.16745693981647491,\n",
       "  0.035298481583595276,\n",
       "  -0.033928144723176956,\n",
       "  -0.1301245540380478,\n",
       "  -0.07134506851434708,\n",
       "  -0.14142200350761414,\n",
       "  -0.18150505423545837,\n",
       "  0.08887521922588348,\n",
       "  -0.09880905598402023,\n",
       "  0.25074806809425354,\n",
       "  -0.029477424919605255,\n",
       "  -0.2514168620109558,\n",
       "  -0.11865878105163574,\n",
       "  -0.05802131071686745,\n",
       "  0.1247931569814682,\n",
       "  -0.20628738403320312,\n",
       "  -0.13798443973064423,\n",
       "  0.0005696872249245644,\n",
       "  -0.08893042802810669,\n",
       "  0.13348783552646637,\n",
       "  0.03435872122645378,\n",
       "  0.09697136282920837,\n",
       "  0.011655408889055252,\n",
       "  -0.09127835929393768,\n",
       "  -0.4120059311389923,\n",
       "  -0.09867683798074722,\n",
       "  -0.12842053174972534,\n",
       "  0.002485324628651142,\n",
       "  -0.07892625778913498,\n",
       "  0.03152521327137947,\n",
       "  0.008021438494324684,\n",
       "  -0.18162468075752258,\n",
       "  -0.019821377471089363,\n",
       "  -0.011953884735703468,\n",
       "  0.02544783614575863,\n",
       "  0.017939290031790733,\n",
       "  0.0017304476350545883,\n",
       "  0.14911764860153198,\n",
       "  -0.0006059017032384872,\n",
       "  -0.19194328784942627,\n",
       "  0.01694880798459053,\n",
       "  0.01405841764062643,\n",
       "  0.295899361371994,\n",
       "  0.14281630516052246,\n",
       "  0.04675420746207237,\n",
       "  0.02688053995370865,\n",
       "  -0.1346018761396408,\n",
       "  0.11437614262104034,\n",
       "  -0.15360070765018463,\n",
       "  0.09647992253303528,\n",
       "  0.17728900909423828,\n",
       "  0.07961538434028625,\n",
       "  -0.008150143548846245,\n",
       "  0.053360141813755035,\n",
       "  -0.05723974108695984,\n",
       "  0.058690641075372696,\n",
       "  0.10813295841217041,\n",
       "  -0.16124384105205536,\n",
       "  0.04187314957380295,\n",
       "  0.15986129641532898,\n",
       "  -0.057311587035655975,\n",
       "  -0.08896686136722565,\n",
       "  -0.053140874952077866,\n",
       "  0.2648686468601227,\n",
       "  0.060893069952726364,\n",
       "  -0.13355028629302979,\n",
       "  -0.1661888062953949,\n",
       "  0.06681457161903381,\n",
       "  -0.11186053603887558,\n",
       "  -0.13633762300014496,\n",
       "  0.08630435168743134,\n",
       "  -0.14348667860031128,\n",
       "  -0.1538531631231308,\n",
       "  -0.30941712856292725,\n",
       "  0.046530649065971375,\n",
       "  0.4554409980773926,\n",
       "  0.05549757555127144,\n",
       "  -0.242030069231987,\n",
       "  0.014783655293285847,\n",
       "  -0.12513631582260132,\n",
       "  0.003922765608876944,\n",
       "  0.14916765689849854,\n",
       "  0.10156316310167313,\n",
       "  -0.04996946454048157,\n",
       "  -0.02052682265639305,\n",
       "  -0.18349666893482208,\n",
       "  -0.020713552832603455,\n",
       "  0.17655403912067413,\n",
       "  -0.06754803657531738,\n",
       "  -0.0780276507139206,\n",
       "  0.27826178073883057,\n",
       "  0.03990232199430466,\n",
       "  0.08805441856384277,\n",
       "  0.05647045001387596,\n",
       "  0.09127599745988846,\n",
       "  -0.13184240460395813,\n",
       "  -0.01062558963894844,\n",
       "  -0.11547520011663437,\n",
       "  -0.07688077539205551,\n",
       "  0.07120885699987411,\n",
       "  -0.05465361475944519,\n",
       "  -0.11664987355470657,\n",
       "  0.08297216147184372,\n",
       "  -0.1643497794866562,\n",
       "  0.14673654735088348,\n",
       "  0.010884227231144905,\n",
       "  0.03597953915596008,\n",
       "  0.03805702552199364,\n",
       "  -0.020038243383169174,\n",
       "  -0.10165510326623917,\n",
       "  -0.13007965683937073,\n",
       "  0.09703575074672699,\n",
       "  -0.26612088084220886,\n",
       "  0.16569118201732635,\n",
       "  0.18596301972866058,\n",
       "  0.10719675570726395,\n",
       "  0.15164342522621155,\n",
       "  0.09624433517456055,\n",
       "  0.05414784699678421,\n",
       "  -0.044358447194099426,\n",
       "  -0.048468515276908875,\n",
       "  -0.18303640186786652,\n",
       "  -0.07384836673736572,\n",
       "  0.09194806218147278,\n",
       "  -0.008906582370400429,\n",
       "  -0.01605525240302086,\n",
       "  -0.014216212555766106): '23140736-BCU'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{ tuple(np.load('./database/face_encodings/'+encoded_face_id)):encoded_face_id.split('.')[0] for encoded_face_id in os.listdir('./database/face_encodings/') }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 79\u001b[0m\n\u001b[0;32m     77\u001b[0m         cap\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m     78\u001b[0m         cv2\u001b[39m.\u001b[39mdestroyAllWindows()\n\u001b[1;32m---> 79\u001b[0m Session \u001b[39m=\u001b[39m Attendance()\n\u001b[0;32m     80\u001b[0m Session\u001b[39m.\u001b[39mstart_session()\n",
      "Cell \u001b[1;32mIn[8], line 17\u001b[0m, in \u001b[0;36mAttendance.__init__\u001b[1;34m(self, scale_frame, face_location_model, face_encoding_model)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Retrieves and retuns dictionary (key is face enoding and value is the student id) of faces encoding from the server'''\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     \u001b[39mreturn\u001b[39;00m { np\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39m./database/face_encodings/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mencoded_face_id):encoded_face_id\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m encoded_face_id \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(\u001b[39m'\u001b[39m\u001b[39m./database/face_encodings/\u001b[39m\u001b[39m'\u001b[39m) }\n\u001b[1;32m---> 17\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__encodings_database \u001b[39m=\u001b[39m retrieve_faces_encodings()\n\u001b[0;32m     19\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__identified_student_ids \u001b[39m=\u001b[39m []\n\u001b[0;32m     20\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscale_frame \u001b[39m=\u001b[39m scale_frame\n",
      "Cell \u001b[1;32mIn[8], line 15\u001b[0m, in \u001b[0;36mAttendance.__init__.<locals>.retrieve_faces_encodings\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mretrieve_faces_encodings\u001b[39m():\n\u001b[0;32m     14\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Retrieves and retuns dictionary (key is face enoding and value is the student id) of faces encoding from the server'''\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     \u001b[39mreturn\u001b[39;00m { np\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39m./database/face_encodings/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mencoded_face_id):encoded_face_id\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m encoded_face_id \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(\u001b[39m'\u001b[39m\u001b[39m./database/face_encodings/\u001b[39m\u001b[39m'\u001b[39m) }\n",
      "Cell \u001b[1;32mIn[8], line 15\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mretrieve_faces_encodings\u001b[39m():\n\u001b[0;32m     14\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Retrieves and retuns dictionary (key is face enoding and value is the student id) of faces encoding from the server'''\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     \u001b[39mreturn\u001b[39;00m { np\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39m./database/face_encodings/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mencoded_face_id):encoded_face_id\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m encoded_face_id \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(\u001b[39m'\u001b[39m\u001b[39m./database/face_encodings/\u001b[39m\u001b[39m'\u001b[39m) }\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import sys\n",
    "import os\n",
    "\n",
    "class Attendance:\n",
    "\n",
    "    def __init__(self, scale_frame=0.5, face_location_model='hog', face_encoding_model = 'small'):\n",
    "\n",
    "        def retrieve_faces_encodings():\n",
    "            '''Retrieves and retuns dictionary (key is face enoding and value is the student id) of faces encoding from the server'''\n",
    "            return { np.load('./database/face_encodings/'+encoded_face_id):encoded_face_id.split('-')[0] for encoded_face_id in os.listdir('./database/face_encodings/') }\n",
    "\n",
    "        self.__encodings_database = retrieve_faces_encodings()\n",
    "\n",
    "        self.__identified_student_ids = []\n",
    "        self.scale_frame = scale_frame\n",
    "\n",
    "        self.process_current_frame = True\n",
    "        self.face_location_model = face_location_model #'cnn' has better accuracy but uses GPU, 'hog' is faster with less accuracy uses cpu\n",
    "        self.face_encoding_model = face_encoding_model #'large' model has better accuracy but is slower, 'small' model is faster\n",
    "\n",
    "    # def read_image_path(img_path: str) -> np.array:\n",
    "    #     '''Reads given image path and returns its numpy array representation'''\n",
    "    #     return cv2.imread(img_path)\n",
    "\n",
    "    def image_array_to_face_encoding(image_numpy_arr: np.array) -> np.array:\n",
    "        '''Inputs numpy array representation of an image and returns the 122 dimentional (numpy) encoding of every faces in the picture in a list'''\n",
    "        return face_recognition.face_encodings(image_numpy_arr)\n",
    "    \n",
    "    def start_session(self, camera_index=0):\n",
    "        self.__encodings_database_encodings_only = [self.__encodings_database.keys()] # Getting faces encodings only from the database\n",
    "        cap = cv2.VideoCapture(camera_index)\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            small_frame = cv2.resize(frame, (0, 0), fx=self.scale_frame, fy=self.scale_frame) # Resize the frame for faster processing\n",
    "            rgb_frame = small_frame[:, :, ::-1] # Convert the frame from BGR to RGB\n",
    "\n",
    "            face_locations = face_recognition.face_locations(rgb_frame, model=self.face_location_model) # Find face locations and face encodings in the frame\n",
    "            face_encodings = face_recognition.face_encodings(rgb_frame, face_locations) # Generate encodings of every faces in the frame in a list\n",
    "            \n",
    "            for face_encoding in face_encodings:\n",
    "                matches = face_recognition.compare_faces(self.__encodings_database_encodings_only, face_encoding) # Compare the face encoding with the list of known encoded faces\n",
    "                if True in matches:\n",
    "                    match_index = matches.index(True)\n",
    "                    identity = self.__encodings_database_encodings_only[match_index]\n",
    "                else:\n",
    "                    identity = 'Unknown'\n",
    "\n",
    "                self.__identified_student_ids.append(identity)\n",
    "\n",
    "            print(self.__identified_student_ids)\n",
    "            self.__identified_student_ids = []\n",
    "\n",
    "\n",
    "            \n",
    "            # Draw rectangles around detected faces and display names\n",
    "            for (top, right, bottom, left) in face_locations:\n",
    "                top *= int(1 / self.scale_frame)\n",
    "                right *= int(1 / self.scale_frame)\n",
    "                bottom *= int(1 / self.scale_frame)\n",
    "                left *= int(1 / self.scale_frame)\n",
    "                cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "            \n",
    "            # Display the frame with face rectangles\n",
    "            cv2.imshow('Face Detection', frame)\n",
    "            \n",
    "            # Break the loop if 'q' key is pressed\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        # Release the camera and close the window\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "Session = Attendance()\n",
    "Session.start_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "\n",
    "# face_encodings_path = './database/face_encodings/'\n",
    "# known_faces = [ np.load(face_encodings_path+encoded_face) for encoded_face in os.listdir(face_encodings_path) ]\n",
    "# known_faces[0].shape\n",
    "\n",
    "tuple(np.array([1,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "['Unknown']\n",
      "['Unknown']\n",
      "['Unknown']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "['Unknown']\n",
      "['Unknown']\n",
      "['Unknown']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "['Unknown']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "['Unknown']\n",
      "['Unknown']\n",
      "['Unknown']\n",
      "['Unknown']\n",
      "['Unknown']\n",
      "['Unknown']\n",
      "['Unknown']\n",
      "['Unknown']\n",
      "['Unknown']\n",
      "['Unknown']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0]\n",
      "[]\n",
      "[0]\n",
      "[]\n",
      "[0]\n",
      "[0]\n",
      "[]\n",
      "[0]\n",
      "[0]\n",
      "[]\n",
      "[0]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0]\n",
      "[0]\n",
      "[]\n",
      "[]\n",
      "[0]\n",
      "[0]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[]\n",
      "[0]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0]\n",
      "[]\n",
      "[0]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "['Unknown']\n",
      "['Unknown']\n",
      "[]\n",
      "[0]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0]\n",
      "['Unknown']\n",
      "[]\n",
      "['Unknown']\n",
      "['Unknown']\n",
      "['Unknown']\n",
      "['Unknown']\n",
      "['Unknown']\n",
      "['Unknown']\n",
      "['Unknown']\n",
      "[]\n",
      "['Unknown']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0]\n",
      "[]\n",
      "['Unknown']\n",
      "[0, 'Unknown']\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "\n",
    "def read_image_path(img_path: str) -> np.array:\n",
    "    return cv2.imread(img_path)\n",
    "\n",
    "def image_array_to_face_encoding(image_numpy_arr: np.array) -> np.array:\n",
    "    return face_recognition.face_encodings(image_numpy_arr)\n",
    "\n",
    "def run_recognization(scale_frame=0.5, preview=True):\n",
    "\n",
    "    if preview==True:\n",
    "        # Open the default camera (usually the built-in webcam)\n",
    "        cap = cv2.VideoCapture(0)\n",
    "\n",
    "        target = []\n",
    "\n",
    "        while True:\n",
    "            # Capture a frame from the camera\n",
    "            ret, frame = cap.read()\n",
    "            \n",
    "            # Resize the frame for faster processing\n",
    "            small_frame = cv2.resize(frame, (0, 0), fx=scale_frame, fy=scale_frame)\n",
    "            \n",
    "            # Convert the frame from BGR to RGB\n",
    "            rgb_frame = small_frame[:, :, ::-1]\n",
    "            \n",
    "            # Find face locations and face encodings in the frame\n",
    "            face_locations = face_recognition.face_locations(rgb_frame)\n",
    "            face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "            # print(len(face_encodings), face_encodings)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # Initialize the match status as \"Unknown\"\n",
    "            match_status = None\n",
    "            \n",
    "            # Match detected faces against known faces\n",
    "            for face_encoding in face_encodings:\n",
    "                # Compare the face encoding with the list of known encoded faces\n",
    "                matches = face_recognition.compare_faces(known_faces, face_encoding)\n",
    "                # print(len(matches), matches)\n",
    "                \n",
    "                if True in matches:\n",
    "                    # match_indexes = [idx for idx, value in enumerate(matches) if value is True]\n",
    "\n",
    "                    match_status = matches.index(True)\n",
    "                    # print(match_indexes)\n",
    "                else:\n",
    "                    match_status = 'Unknown'\n",
    "\n",
    "                target.append(match_status)\n",
    "\n",
    "            print(target)\n",
    "            target = []\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            # Draw rectangles around detected faces and display names\n",
    "            for (top, right, bottom, left) in face_locations:\n",
    "                top *= int(1 / scale_frame)\n",
    "                right *= int(1 / scale_frame)\n",
    "                bottom *= int(1 / scale_frame)\n",
    "                left *= int(1 / scale_frame)\n",
    "                cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "            \n",
    "            # Display the frame with face rectangles\n",
    "            cv2.imshow('Face Detection', frame)\n",
    "            \n",
    "            # Break the loop if 'q' key is pressed\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        # Release the camera and close the window\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "    else:\n",
    "        False\n",
    "\n",
    "run_recognization()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "+"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
