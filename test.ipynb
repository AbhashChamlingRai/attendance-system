{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FACE DETECTION] 1 faces detected at 11:56:16.\n",
      "[FACE DETECTION] 1 faces detected at 11:56:18.\n",
      "[FACE DETECTION] 1 faces detected at 11:56:20.\n",
      "[FACE DETECTION] 1 faces detected at 11:56:22.\n",
      "[FACE DETECTION] 1 faces detected at 11:56:24.\n",
      "[FACE DETECTION] 1 faces detected at 11:56:26.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "import datetime\n",
    "import face_recognition\n",
    "\n",
    "class Session:\n",
    "\n",
    "    def __init__(self, face_location_model='hog', face_encoding_model = 'small'):\n",
    "\n",
    "        self.face_location_model = face_location_model #'cnn' has better accuracy but uses GPU, 'hog' is faster with less accuracy uses cpu\n",
    "        self.face_encoding_model = face_encoding_model #'large' model has better accuracy but is slower, 'small' model is faster\n",
    "\n",
    "        self.__face_encodings_pkl_path = './database/known_face_encodings'\n",
    "        with open(self.__face_encodings_pkl_path, 'rb') as file:\n",
    "            self.__known_face_encodings = pickle.load(file)\n",
    "\n",
    "    def get_current_time(self) -> str:\n",
    "        '''Gets the current timestamp with seconds precision, converts it to string, and returns it'''\n",
    "        return datetime.datetime.now().strftime('%H:%M:%S')\n",
    "\n",
    "    def compare_faces(self, known: dict, unknown, tolerance=0.6):\n",
    "        for student_identity, face_encoding in known.items():\n",
    "            if True in face_recognition.api.compare_faces(face_encoding, unknown, tolerance=tolerance):\n",
    "                return student_identity\n",
    "        return None\n",
    "\n",
    "    def start_session(self, camera_index=0, show_preview=True, scale_frame=0.75, desired_fps=2, tolerance=0.6):\n",
    "        try:\n",
    "\n",
    "            cap = cv2.VideoCapture(camera_index)\n",
    "            frame_delay = int(1000 / desired_fps)  # Delay in milliseconds between frames based on the desired FPS\n",
    "            \n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "\n",
    "                small_frame = cv2.resize(frame, (0, 0), fx=scale_frame, fy=scale_frame) # Resize the frame for faster processing\n",
    "                rgb_frame = small_frame[:, :, ::-1] # Convert the frame from BGR to RGB\n",
    "\n",
    "                face_locations = face_recognition.face_locations(rgb_frame, model=self.face_location_model) # Find face locations and face encodings in the frame\n",
    "                unknown_face_encodings = face_recognition.face_encodings(rgb_frame, face_locations) # Generate encodings of every faces in the frame in a list\n",
    "                number_of_faces_detected = len(unknown_face_encodings)\n",
    "\n",
    "                self.__identified_student_ids = []\n",
    "\n",
    "                if number_of_faces_detected != 0: # Send data only if one or more person is detected\n",
    "                    time = self.get_current_time()\n",
    "                    print(f'[FACE DETECTION] {number_of_faces_detected} faces detected at {time}.')\n",
    "                    for unknown_face in unknown_face_encodings:\n",
    "                        id = self.compare_faces(self.__known_face_encodings, unknown_face, tolerance=tolerance)\n",
    "                        if id is None:\n",
    "                            id = 'Unknown'\n",
    "                        self.__identified_student_ids.append(id)\n",
    "\n",
    "                if show_preview == True: \n",
    "                    # Draw rectangles around detected faces and display names on 'the scaled frame'\n",
    "                    for (top, right, bottom, left), identity in zip(face_locations, self.__identified_student_ids):\n",
    "                        cv2.rectangle(small_frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "                        cv2.putText(small_frame, identity, (left, bottom + 20), cv2.FONT_HERSHEY_DUPLEX, 0.5, (0, 255, 0), 1)\n",
    "                    \n",
    "                    cv2.imshow('Face Detection (Scaled Frames)', small_frame) # Display the frame with face rectangles\n",
    "                    \n",
    "                    if cv2.waitKey(frame_delay) & 0xFF == ord('q'): # Break the loop if 'q' key is pressed\n",
    "                        break\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            pass  # Handle keyboard interrupt (e.g., for clean exit)\n",
    "\n",
    "        finally:\n",
    "            cap.release()  # Release the camera\n",
    "            cv2.destroyAllWindows()  # Close OpenCV windows\n",
    "\n",
    "a = Session()\n",
    "a.start_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
